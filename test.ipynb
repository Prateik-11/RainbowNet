{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's in the dataset: 4672 | Number of 0's: 477097408\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_ones_in_npy(file_path):\n",
    "    try:\n",
    "        # Load the numpy array from the .npy file\n",
    "        data = np.load(file_path)\n",
    "\n",
    "        # Count the number of occurrences of 1 in the dataset\n",
    "        ones_count = np.count_nonzero(data == 1)\n",
    "        zero_count = np.count_nonzero(data == 0)\n",
    "\n",
    "        print(f\"Number of 1's in the dataset: {ones_count} | Number of 0's: {zero_count}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing the file: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/home/prateiksinha/rainbench_finetune/data/rainbow.npy'  # Replace with the path to your .npy file\n",
    "count_ones_in_npy(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array:\n",
      "(14560, 1, 128, 256)\n",
      "\n",
      "Filtered Array:\n",
      "(2834, 1, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "def filter_elements_with_one(arr):\n",
    "    # Check if any element in the second or third axis has a value of 1\n",
    "    mask = np.any((arr[:, 0, :, :] == 1), axis=(1, 2))\n",
    "\n",
    "\n",
    "    # Return elements along the first axis where the condition is True\n",
    "    result = arr[mask]\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "array_data = np.load(file_path)\n",
    "filtered_array = filter_elements_with_one(array_data)\n",
    "\n",
    "print(\"Original Array:\")\n",
    "print(array_data.shape)\n",
    "print(\"\\nFiltered Array:\")\n",
    "print(filtered_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87360.0\n",
      "14560.0\n"
     ]
    }
   ],
   "source": [
    "# min: 2004-02-11\n",
    "# max: 2013-12-07\n",
    "\n",
    "dt_str = datetime(2004, 1, 1, 0, 0, 0)\n",
    "dt_end = datetime(2013, 12, 19, 0, 0, 0)\n",
    "\n",
    "hours_diff = (dt_end - dt_str).total_seconds() / 3600\n",
    "print(hours_diff)\n",
    "\n",
    "print(hours_diff / 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take the index (out of 14560) --> map to corresponding npz entry (in dataset)\n",
    "\n",
    "def belle(idx): \n",
    "    idx_sec = idx * 3600 * 6\n",
    "    dt_new = dt_str + timedelta(seconds=idx_sec)\n",
    "\n",
    "    year = dt_new.year \n",
    "    dt_yr = datetime(year, 1, 1, 0, 0, 0)\n",
    "\n",
    "    time_elapsed = (dt_new - dt_yr).total_seconds() / 3600\n",
    "    print(f\"We are {time_elapsed} hours into {year}.\")\n",
    "\n",
    "    if (time_elapsed >= 8736): \n",
    "        time_elapsed = 8730\n",
    "\n",
    "    shard_num = int(time_elapsed / (273))\n",
    "    entry_num = int(time_elapsed % (273))\n",
    "\n",
    "    print(f\"So, we're looking for entry {entry_num} in '{year}_{shard_num}.npy'\")\n",
    "\n",
    "    return entry_num, f\"{year}_{shard_num}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are 0.0 hours into 2005.\n",
      "So, we're looking for entry 0 in '2005_0.npy'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, '2005_0.npy')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belle(1464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orography, (273, 1, 128, 256)\n",
      "land_sea_mask, (273, 1, 128, 256)\n",
      "lattitude, (273, 1, 128, 256)\n",
      "temperature_50, (273, 1, 128, 256)\n",
      "temperature_250, (273, 1, 128, 256)\n",
      "temperature_500, (273, 1, 128, 256)\n",
      "temperature_600, (273, 1, 128, 256)\n",
      "temperature_700, (273, 1, 128, 256)\n",
      "temperature_850, (273, 1, 128, 256)\n",
      "temperature_925, (273, 1, 128, 256)\n",
      "geopotential_50, (273, 1, 128, 256)\n",
      "geopotential_250, (273, 1, 128, 256)\n",
      "geopotential_500, (273, 1, 128, 256)\n",
      "geopotential_600, (273, 1, 128, 256)\n",
      "geopotential_700, (273, 1, 128, 256)\n",
      "geopotential_850, (273, 1, 128, 256)\n",
      "geopotential_925, (273, 1, 128, 256)\n",
      "u_component_of_wind_50, (273, 1, 128, 256)\n",
      "u_component_of_wind_250, (273, 1, 128, 256)\n",
      "u_component_of_wind_500, (273, 1, 128, 256)\n",
      "u_component_of_wind_600, (273, 1, 128, 256)\n",
      "u_component_of_wind_700, (273, 1, 128, 256)\n",
      "u_component_of_wind_850, (273, 1, 128, 256)\n",
      "u_component_of_wind_925, (273, 1, 128, 256)\n",
      "v_component_of_wind_50, (273, 1, 128, 256)\n",
      "v_component_of_wind_250, (273, 1, 128, 256)\n",
      "v_component_of_wind_500, (273, 1, 128, 256)\n",
      "v_component_of_wind_600, (273, 1, 128, 256)\n",
      "v_component_of_wind_700, (273, 1, 128, 256)\n",
      "v_component_of_wind_850, (273, 1, 128, 256)\n",
      "v_component_of_wind_925, (273, 1, 128, 256)\n",
      "specific_humidity_50, (273, 1, 128, 256)\n",
      "specific_humidity_250, (273, 1, 128, 256)\n",
      "specific_humidity_500, (273, 1, 128, 256)\n",
      "specific_humidity_600, (273, 1, 128, 256)\n",
      "specific_humidity_700, (273, 1, 128, 256)\n",
      "specific_humidity_850, (273, 1, 128, 256)\n",
      "specific_humidity_925, (273, 1, 128, 256)\n",
      "relative_humidity_50, (273, 1, 128, 256)\n",
      "relative_humidity_250, (273, 1, 128, 256)\n",
      "relative_humidity_500, (273, 1, 128, 256)\n",
      "relative_humidity_600, (273, 1, 128, 256)\n",
      "relative_humidity_700, (273, 1, 128, 256)\n",
      "relative_humidity_850, (273, 1, 128, 256)\n",
      "relative_humidity_925, (273, 1, 128, 256)\n",
      "2m_temperature, (273, 1, 128, 256)\n",
      "10m_u_component_of_wind, (273, 1, 128, 256)\n",
      "10m_v_component_of_wind, (273, 1, 128, 256)\n",
      "toa_incident_solar_radiation, (273, 1, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "path = '/localhome/data/datasets/climate/era5/1.40625_npz/train/1979_0.npz'\n",
    "\n",
    "data = np.load(path)\n",
    "for key in data.files: \n",
    "    print(f\"{key}, {data[key].shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climaX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
